{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c99308",
      "metadata": {
        "id": "20c99308"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def close_window_os():\n",
        "    cv2.destroyAllWindows()\n",
        "    for i in range (1,5): #trick for closing the display window on macos\n",
        "        cv2.waitKey(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47aabb5c",
      "metadata": {
        "id": "47aabb5c"
      },
      "outputs": [],
      "source": [
        "# Problem 1\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "def getFaceLocation():\n",
        "\n",
        "    camera = cv2.VideoCapture(0)\n",
        "    facecascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    ret = True\n",
        "\n",
        "#     #Refresh the camera\n",
        "    for i in range(5):\n",
        "        ret, frame = camera.read()\n",
        "\n",
        "    while(ret):\n",
        "        ret, frame = camera.read()\n",
        "        if ret == True:\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            face_coordinates = facecascade.detectMultiScale(gray, 1.3, 4)\n",
        "\n",
        "\n",
        "            cv2.imshow('frames', frame)\n",
        "            cv2.waitKey(1)\n",
        "            if len(face_coordinates) > 0:\n",
        "                (a, b, w, h) = face_coordinates[0]\n",
        "                camera.release()\n",
        "                close_window_os()\n",
        "\n",
        "                return frame[b:b+h, a:a+w,:], (a, b, w, h)\n",
        "        else:\n",
        "            print('error')\n",
        "            break\n",
        "\n",
        "\n",
        "face_image, face_location = getFaceLocation()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97492364",
      "metadata": {
        "id": "97492364"
      },
      "outputs": [],
      "source": [
        "#Problem 2\n",
        "def face_tracking(template, method):\n",
        "    ret = True\n",
        "    camera = cv2.VideoCapture(0)\n",
        "\n",
        "    #Refresh the camera\n",
        "    for i in range(5):\n",
        "        ret, frame = camera.read()\n",
        "\n",
        "\n",
        "    # Perform match operations.\n",
        "    template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    while(ret):\n",
        "        ret, frame = camera.read()\n",
        "        if ret == True:\n",
        "            img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            # Store width and height of template in w and h\n",
        "\n",
        "\n",
        "        w, h = template.shape[::-1]\n",
        "        res = cv2.matchTemplate(img_gray, template, method)\n",
        "\n",
        "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
        "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
        "        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
        "            top_left = min_loc\n",
        "        else:\n",
        "            top_left = max_loc\n",
        "\n",
        "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
        "\n",
        "        cv2.rectangle(frame,top_left, bottom_right, 255, 2)\n",
        "        cv2.imshow('template', template)\n",
        "        cv2.imshow('frames', frame)\n",
        "\n",
        "        #update template ......\n",
        "#         template = frame[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0],:]\n",
        "\n",
        "        if cv2.waitKey(1) == 27:\n",
        "            break\n",
        "    camera.release()\n",
        "    close_window_os()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3efcde8e",
      "metadata": {
        "id": "3efcde8e"
      },
      "outputs": [],
      "source": [
        "face_tracking(face_image, cv2.TM_CCOEFF_NORMED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d288c2d",
      "metadata": {
        "id": "2d288c2d"
      },
      "outputs": [],
      "source": [
        "close_window_os()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac845beb",
      "metadata": {
        "id": "ac845beb"
      },
      "outputs": [],
      "source": [
        "#problem 3\n",
        "\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import argparse\n",
        "\n",
        "cap = cv.VideoCapture(0)\n",
        "# cap = cv.VideoCapture(\"/Users/vutl2004gmail.com/Downloads/slow_traffic_small.mp4\")\n",
        "\n",
        "#Refresh the camera\n",
        "for i in range(5):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "# take first frame of the video\n",
        "ret,frame = cap.read()\n",
        "\n",
        "# setup initial location of window\n",
        "x, y, w, h = face_location # simply hardcoded the values\n",
        "track_window = (x, y, w, h)\n",
        "\n",
        "# set up the ROI for tracking\n",
        "roi = frame[y:y+h, x:x+w]\n",
        "\n",
        "\n",
        "hsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
        "mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
        "roi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
        "cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n",
        "\n",
        "# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
        "term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\n",
        "\n",
        "while(1):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret == True:\n",
        "        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
        "        dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
        "\n",
        "        # apply meanshift to get the new location\n",
        "        ret, track_window = cv.meanShift(dst, track_window, term_crit)\n",
        "\n",
        "        # Draw it on image\n",
        "        x,y,w,h = track_window\n",
        "        img2 = cv.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n",
        "        cv.imshow('img2',img2)\n",
        "\n",
        "        k = cv.waitKey(30) & 0xff\n",
        "        if k == 27:\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "close_window_os()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9edc128c",
      "metadata": {
        "id": "9edc128c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import argparse\n",
        "\n",
        "def object_tracking_camera_file():\n",
        "    cap = cv.VideoCapture(0)\n",
        "\n",
        "    #Refresh the camera\n",
        "    for i in range(5):\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "    # take first frame of the video\n",
        "    ret,frame = cap.read()\n",
        "\n",
        "\n",
        "    # setup initial location of window\n",
        "    x, y, w, h = (524, 309, 293, 293) # simply hardcoded the values\n",
        "    track_window = (x, y, w, h)\n",
        "\n",
        "    # set up the ROI for tracking\n",
        "    roi = frame[y:y+h, x:x+w]\n",
        "\n",
        "    hsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
        "    mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
        "    roi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
        "    cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n",
        "\n",
        "    # Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
        "    term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\n",
        "\n",
        "    while(1):\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if ret == True:\n",
        "            hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
        "            dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
        "\n",
        "            # apply meanshift to get the new location\n",
        "            ret, track_window = cv.meanShift(dst, track_window, term_crit)\n",
        "#             ret, track_window = cv.CamShift(dst, track_window, term_crit)\n",
        "\n",
        "\n",
        "            # Draw it on image\n",
        "            x,y,w,h = track_window\n",
        "            img2 = cv.rectangle(frame, (x,y), (x+w,y+h), (255, 255, 0) ,4)\n",
        "            cv.imshow('img2',img2)\n",
        "\n",
        "            k = cv.waitKey(30) & 0xff\n",
        "            if k == 27:\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    close_window_os()\n",
        "\n",
        "object_tracking_camera_file()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da7777b",
      "metadata": {
        "id": "4da7777b",
        "outputId": "bd587151-9832-4850-ee4d-d0670c2227cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "875\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import argparse\n",
        "\n",
        "def object_tracking_video_file():\n",
        "    cap = cv.VideoCapture(\"/Users/vutl2004gmail.com/Downloads/8169005713089002738.mp4\")\n",
        "\n",
        "    # take first frame of the video\n",
        "    ret,frame = cap.read()\n",
        "\n",
        "\n",
        "    # setup initial location of window\n",
        "    x, y, w, h = (300, 400, 200, 200) # simply hardcoded the values\n",
        "    track_window = (x, y, w, h)\n",
        "\n",
        "    # set up the ROI for tracking\n",
        "    roi = frame[y:y+h, x:x+w]\n",
        "\n",
        "    hsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
        "    mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
        "    roi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
        "    cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n",
        "\n",
        "    # Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
        "    term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\n",
        "\n",
        "    history = []\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    height, width, layers = frame.shape\n",
        "\n",
        "    # Define the codec and create a VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for mp4 file\n",
        "    fps = 30  # Frames per second\n",
        "    video_file = 'output_video.mp4'\n",
        "    out = cv2.VideoWriter(video_file, fourcc, fps, (width, height))\n",
        "\n",
        "\n",
        "\n",
        "    while(1):\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if ret == True:\n",
        "            hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
        "            dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
        "\n",
        "            # apply meanshift to get the new location\n",
        "            ret, track_window = cv.meanShift(dst, track_window, term_crit)\n",
        "#             ret, track_window = cv.CamShift(dst, track_window, term_crit)\n",
        "\n",
        "\n",
        "\n",
        "            # Draw it on image\n",
        "            x,y,w,h = track_window\n",
        "            img2 = cv.rectangle(frame, (x,y), (x+w,y+h), (255, 255, 0) ,4)\n",
        "            history.append((x+int(w/2),y+int(h/2)))\n",
        "\n",
        "            if (len(history) >= 2):\n",
        "                for i in range(len(history)-1):\n",
        "                    (x,y) = history[i]\n",
        "                    img2 = cv2.line(frame, history[i], history[i+1], (0,0,255), 2)\n",
        "\n",
        "\n",
        "            cv.imshow('img2',img2)\n",
        "            out.write(img2)\n",
        "\n",
        "            k = cv.waitKey(1)\n",
        "#             k = cv.waitKey(0) & 0xff\n",
        "#             if k == 27:\n",
        "#                 break\n",
        "        else:\n",
        "            break\n",
        "    out.release()\n",
        "    print(len(history))\n",
        "    cap.release()\n",
        "    close_window_os()\n",
        "\n",
        "object_tracking_video_file()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}